# SF - ПРОЕКТ 4. Компьютер говорит "НЕТ"

## Цели проекта: 
 - создание работающей модели по предсказанию дэфолта у клиентов банка
 - тренировка навыков по использованию ML в реальных ситуациях


## Задачи проекта:
- совершенствование навыков по предобработке и анализе данных
- примениние разных инструментов для улучшения качества модели
- выбор оптимнальных комбинаций признаков и инструментов для оптимального результата


## Краткая информация о входных данных
client_id - идентификатор клиента

education - уровень образования

sex - пол заемщика

age - возраст заемщика

car - флаг наличия автомобиля

car_type - флаг автомобиля иномарки

decline_app_cnt - количество отказанных прошлых заявок

good_work - флаг наличия “хорошей” работы

bki_request_cnt - количество запросов в БКИ

home_address - категоризатор домашнего адреса

work_address - категоризатор рабочего адреса

income - доход заемщика

foreign_passport - наличие загранпаспорта

sna - связь заемщика с клиентами банка

first_time - давность наличия информации о заемщике

score_bki - скоринговый балл по данным из БКИ

region_rating - рейтинг региона

app_date - дата подачи заявки

default - флаг дефолта по кредиту

## Информация об обработке данных по следующим признакам:
* client_id - удален так как не несет полезной информации для машинного обучения
* education - перекодирован в числовой вид
* decline_app_cnt - прологарифмирован в виду наличия "жирных хвостов"
* income - прологарифмирован в виду наличия "жирных хвостов"
* бинарные признаки (см. список ниже) были перекодированы с применением LabelEcoder
* категориальные признаки (см. список ниже) были перекодированы с использованием OneHotEncoder


## Созданные новые признаки (Feature engineering):
* app_date_month - месяц подачи заявки на кредит
* max_income_age - максимальный доход по возрасту
* mean_request_by_age - среднее количество BKI запросов по возрасту
* mean_request_by_income - среднее количество BKI запросов по доходу
* income_in_region - 1 если доход выше по региону, иначе 0

## Признаки, которые использовались для построения модели:
остальные не использовались в виду высокой корреляции между некоторыми признаками
__бинарные__ <br>
'sex','car','car_type', 'good_work', 'foreign_passport','income_in_region'

__категориальные__ <br>
'education', 'home_address'

__числовые__ <br>
'age', 'income', 'bki_request_cnt', 'sna', 'first_time', 'score_bki', 'region_rating', 'app_date_month', 'decline_app_cnt','mean_request_by_income'


## Подготовка данных к машинному обучению
* Данные для обучения были разделены на обучающие и валидационные с применением метода train_test_split. Валидационная выборка составила 15%.
* Стандартизация проведена с применением StandardScaler()

## Обучение
* "Наивная" моделью была выбрана LogisticRegression() с параметром max_iter=1000
* Улучшенной моделью являлась также LogisticRegression(max_iter=1000), но с дополнительным параметром class_weight='balanced', который помог сбалансировать выборку по целевой переменной default
* В процессе подбора гиперматаметров модели было установлено, что наилучшими являются значения: С=1, penalty='l1'. Изменением параметра solver c ‘liblinear’ на ‘saga’ не приводит к изменению результата модели

## Результаты обучения
Для оценки качества обучения использовались несколько метрик, а именно: accuracy, roc_auc_score, precision, recall, f1-score.
Также для визуальной оценки использовалась confusion_matrix. 
Наилучшие результаты были достигнуты (с оговоркой на поиск лучшего баланса) при следующих значениях обозначенных выше критериев:

accuracy = 0.67     precision   recall   f1-score   

0 - non_default       0.94      0.67      0.78      
1 - default           0.23      0.68      0.34

ROC_AUC = 0.741


## Выводы:
 -  самое большое влияние на предсказательную способность нашей модели оказали признаки, их обработка и комбинации;
 -  некоторые признаки можно было отнести как к числовом переменным так и к категориальным. После преобразований числовые признаки в формате категориальных показали лучшие результаты применения модели логистической регрессии. Последнее позволило высказать гипотезу о том, что при обучении на вход LogisticRegression лучше поставлять по возможности больше категориальных признаков, нежиле обычных числовых;
 -  были предприняты попытки генерации множества признаков, при этом основными переменными для генерации были доход, регион и возраст. Поэтому в итоге получалась большая корреляция между многими признаками и в итоге пришлось отказаться от них;
 -  выборка несбалансированная по целевому признаку. Для решения этой проблемы была предпринята попытка использования сторонней библиотеки imbalanced-learn, а именно класса RandomOverSampler. Выявлено, что результат получился такой же как и со встроенным параметром "class_weight='balanced'" в LogisticRegression, в пользу которого мы и сделали выбор;
 -  поиск лучших параметров регуляризации не привёл к существенному улучшению нашей модели, хотя гиперпараметр penalty изменился с 'l2' на 'l1'. Изменение параметра solver c ‘liblinear’ на ‘saga’ также не изменило результата модели;
 -  добиться приемлимой на наш взгляд предсказательной способности модели несмотря на неплохой ROC, не удалось. Тем не менее, "улучшенная модель" позволяет делать предсказания не в пользу того или иного класса, а с присутствием баланса между ними. Это позволяет избежать одновременно больших значений ошибок первого и второго рода. На наш взгляд такая модель как раз и отражает суть работы банковской системы, которая находит для себя приемлемый баланс между выдачей кредиту и отказом от него заявителю;
 - только преобразование признаков не является достаточным для существенного улучшения модели линейной регрессии. Поэтому в реальных условиях необходимо дополнительно собирать данные.
